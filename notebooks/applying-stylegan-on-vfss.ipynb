{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSONmWBgp_qZ",
        "outputId": "fa800558-6a75-48b9-9439-f42c78ad64e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLX8DKUTfGcL"
      },
      "source": [
        "## Paper: [Training Generative Adversarial Networks with Limited Data](https://arxiv.org/abs/2006.06676)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duVqR9KEfGcL"
      },
      "source": [
        "![](https://github.com/NVlabs/stylegan2-ada-pytorch/raw/main/docs/stylegan2-ada-teaser-1024x252.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ffakUn-fGcL"
      },
      "source": [
        "## Repro [Github](https://github.com/NVlabs/stylegan2-ada-pytorch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-05-19T00:16:30.284992Z",
          "iopub.status.busy": "2025-05-19T00:16:30.284519Z",
          "iopub.status.idle": "2025-05-19T00:20:24.756371Z",
          "shell.execute_reply": "2025-05-19T00:20:24.755128Z",
          "shell.execute_reply.started": "2025-05-19T00:16:30.284796Z"
        },
        "id": "yjGfSsq7fGcL",
        "outputId": "cf38d8ec-85ff-4280-9b64-6bae1511262e",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (8.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Collecting pyspng\n",
            "  Downloading pyspng-0.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting ninja\n",
            "  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting imageio-ffmpeg==0.4.3\n",
            "  Downloading imageio_ffmpeg-0.4.3-py3-none-manylinux2010_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pyspng) (2.0.2)\n",
            "Downloading imageio_ffmpeg-0.4.3-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyspng-0.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (196 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.1/196.1 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyspng, ninja, imageio-ffmpeg\n",
            "  Attempting uninstall: imageio-ffmpeg\n",
            "    Found existing installation: imageio-ffmpeg 0.6.0\n",
            "    Uninstalling imageio-ffmpeg-0.6.0:\n",
            "      Successfully uninstalled imageio-ffmpeg-0.6.0\n",
            "Successfully installed imageio-ffmpeg-0.4.3 ninja-1.11.1.4 pyspng-0.1.3\n"
          ]
        }
      ],
      "source": [
        "!pip install click requests tqdm pyspng ninja imageio-ffmpeg==0.4.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-05-19T00:36:55.67334Z",
          "iopub.status.busy": "2025-05-19T00:36:55.672953Z",
          "iopub.status.idle": "2025-05-19T00:36:57.466248Z",
          "shell.execute_reply": "2025-05-19T00:36:57.464707Z",
          "shell.execute_reply.started": "2025-05-19T00:36:55.673302Z"
        },
        "id": "h7AfOlktfGcM",
        "outputId": "9551f9d8-8407-4c4e-bc0f-40e05ca6d708",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'stylegan3'...\n",
            "remote: Enumerating objects: 212, done.\u001b[K\n",
            "remote: Counting objects: 100% (163/163), done.\u001b[K\n",
            "remote: Compressing objects: 100% (73/73), done.\u001b[K\n",
            "remote: Total 212 (delta 99), reused 90 (delta 90), pack-reused 49 (from 1)\u001b[K\n",
            "Receiving objects: 100% (212/212), 4.16 MiB | 7.42 MiB/s, done.\n",
            "Resolving deltas: 100% (108/108), done.\n",
            "/content/stylegan3\n"
          ]
        }
      ],
      "source": [
        "# add align_images.py\n",
        "# !git clone https://github.com/rkuo2000/stylegan2-ada-pytorch\n",
        "!git clone https://github.com/NVlabs/stylegan3\n",
        "%cd stylegan3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNj_so8cfGcM"
      },
      "source": [
        "## Training new networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOu_wP7bzyzd",
        "outputId": "e8a5c9a6-b806-4e1e-b0d5-bc536ede6dfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100% 100/100 [00:09<00:00, 10.92it/s]\n"
          ]
        }
      ],
      "source": [
        "!python dataset_tool.py --source=/content/drive/MyDrive/Estudo/PUC/INCA/max_constriction/ --dest=../data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-05-19T00:38:15.585104Z",
          "iopub.status.busy": "2025-05-19T00:38:15.584716Z",
          "iopub.status.idle": "2025-05-19T00:38:15.590128Z",
          "shell.execute_reply": "2025-05-19T00:38:15.589077Z",
          "shell.execute_reply.started": "2025-05-19T00:38:15.585065Z"
        },
        "id": "YDC1UxuwfGcM",
        "outputId": "2298e13e-5274-4c95-de82-7e1703afaf49",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
            "\n",
            "Training options:\n",
            "{\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan2.Generator\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 2\n",
            "    },\n",
            "    \"channel_base\": 16384,\n",
            "    \"channel_max\": 512,\n",
            "    \"fused_modconv_default\": \"inference_only\"\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan2.Discriminator\",\n",
            "    \"block_kwargs\": {\n",
            "      \"freeze_layers\": 0\n",
            "    },\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"channel_base\": 16384,\n",
            "    \"channel_max\": 512\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.0025\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.0025\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"r1_gamma\": 0.8192,\n",
            "    \"style_mixing_prob\": 0.9,\n",
            "    \"pl_weight\": 2,\n",
            "    \"pl_no_weight_grad\": true\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"prefetch_factor\": 2,\n",
            "    \"num_workers\": 3\n",
            "  },\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"../data.zip\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 100,\n",
            "    \"xflip\": false,\n",
            "    \"resolution\": 512,\n",
            "    \"random_seed\": 0\n",
            "  },\n",
            "  \"num_gpus\": 1,\n",
            "  \"batch_size\": 16,\n",
            "  \"batch_gpu\": 16,\n",
            "  \"metrics\": [],\n",
            "  \"total_kimg\": 1000,\n",
            "  \"kimg_per_tick\": 4,\n",
            "  \"image_snapshot_ticks\": 50,\n",
            "  \"network_snapshot_ticks\": 50,\n",
            "  \"random_seed\": 0,\n",
            "  \"ema_kimg\": 5.0,\n",
            "  \"G_reg_interval\": 4,\n",
            "  \"augment_kwargs\": {\n",
            "    \"class_name\": \"training.augment.AugmentPipe\",\n",
            "    \"xflip\": 1,\n",
            "    \"rotate90\": 1,\n",
            "    \"xint\": 1,\n",
            "    \"scale\": 1,\n",
            "    \"rotate\": 1,\n",
            "    \"aniso\": 1,\n",
            "    \"xfrac\": 1,\n",
            "    \"brightness\": 1,\n",
            "    \"contrast\": 1,\n",
            "    \"lumaflip\": 1,\n",
            "    \"hue\": 1,\n",
            "    \"saturation\": 1\n",
            "  },\n",
            "  \"ada_target\": 0.6,\n",
            "  \"run_dir\": \"../training-runs/00000-stylegan2-data-gpus1-batch16-gamma0.8192\"\n",
            "}\n",
            "\n",
            "Output directory:    ../training-runs/00000-stylegan2-data-gpus1-batch16-gamma0.8192\n",
            "Number of GPUs:      1\n",
            "Batch size:          16 images\n",
            "Training duration:   1000 kimg\n",
            "Dataset path:        ../data.zip\n",
            "Dataset size:        100 images\n",
            "Dataset resolution:  512\n",
            "Dataset labels:      False\n",
            "Dataset x-flips:     False\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Loading training set...\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/sampler.py:77: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "\n",
            "Num images:  100\n",
            "Image shape: [3, 512, 512]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/stylegan3/train.py\", line 286, in <module>\n",
            "    main() # pylint: disable=no-value-for-parameter\n",
            "    ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1442, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1363, in main\n",
            "    rv = self.invoke(ctx)\n",
            "         ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1226, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 794, in invoke\n",
            "    return callback(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/stylegan3/train.py\", line 281, in main\n",
            "    launch_training(c=c, desc=desc, outdir=opts.outdir, dry_run=opts.dry_run)\n",
            "  File \"/content/stylegan3/train.py\", line 96, in launch_training\n",
            "    subprocess_fn(rank=0, c=c, temp_dir=temp_dir)\n",
            "  File \"/content/stylegan3/train.py\", line 47, in subprocess_fn\n",
            "    training_loop.training_loop(rank=rank, **c)\n",
            "  File \"/content/stylegan3/training/training_loop.py\", line 152, in training_loop\n",
            "    G = dnnlib.util.construct_class_by_name(**G_kwargs, **common_kwargs).train().requires_grad_(False).to(device) # subclass of torch.nn.Module\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1343, in to\n",
            "    return self._apply(convert)\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 903, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 903, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 903, in _apply\n",
            "    module._apply(fn)\n",
            "  [Previous line repeated 1 more time]\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 930, in _apply\n",
            "    param_applied = fn(param)\n",
            "                    ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1329, in convert\n",
            "    return t.to(\n",
            "           ^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py\", line 319, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "Exception ignored in atexit callback: <function _exit_function at 0x7c0cef96d4e0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/multiprocessing/util.py\", line 360, in _exit_function\n",
            "    p.join()\n",
            "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 149, in join\n",
            "    res = self._popen.wait(timeout)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/multiprocessing/popen_fork.py\", line 43, in wait\n",
            "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/multiprocessing/popen_fork.py\", line 27, in poll\n",
            "    pid, sts = os.waitpid(self.pid, flag)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/signal_handling.py\", line 73, in handler\n",
            "    _error_if_any_worker_fails()\n",
            "RuntimeError: DataLoader worker (pid 2507) is killed by signal: Terminated. \n"
          ]
        }
      ],
      "source": [
        "# !python train.py --outdir=~/training-runs --data=../data.zip --cfg=stylegan2 --gpus=1 --batch=16 --gamma=0.8192 --map-depth=2 --glr=0.0025 --dlr=0.0025 --cbase=16384\n",
        "\n",
        "!python train.py \\\n",
        "  --outdir=../training-runs \\\n",
        "  --data=../data.zip \\\n",
        "  --cfg=stylegan2 \\\n",
        "  --gpus=1 \\\n",
        "  --batch=16 \\\n",
        "  --gamma=0.8192 \\\n",
        "  --map-depth=2 \\\n",
        "  --glr=0.0025 \\\n",
        "  --dlr=0.0025 \\\n",
        "  --cbase=16384 \\\n",
        "  --kimg=1000 \\\n",
        "  --metrics=none \\\n",
        "  # --tick=1 \\\n",
        "  --snap=5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-i78eQxBr36W"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKbdO_LNfGcM"
      },
      "source": [
        "## Generate\n",
        "Pre-trained networks are stored as *.pkl files that can be referenced using local filenames or URLs:\n",
        "\n",
        "* Generate curated MetFaces images without truncation (Fig.10 left)\n",
        "\n",
        "    python generate.py --outdir=out --trunc=1 --seeds=85,265,297,849 \\\n",
        "    --network=https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/metfaces.pkl\n",
        "\n",
        "* Generate uncurated MetFaces images with truncation (Fig.12 upper left)\n",
        "\n",
        "    python generate.py --outdir=out --trunc=0.7 --seeds=600-605 \\\n",
        "    --network=https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/metfaces.pkl\n",
        "\n",
        "* Generate class conditional CIFAR-10 images (Fig.17 left, Car)\n",
        "\n",
        "    python generate.py --outdir=out --seeds=0-35 --class=1 \\\n",
        "    --network=https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/cifar10.pkl\n",
        "\n",
        "* Style mixing example\n",
        "\n",
        "    python style_mixing.py --outdir=out --rows=85,100,458,1500 --cols=55,821,1789,293 \\\n",
        "    --network=https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/metfaces.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMojet9UXzZY"
      },
      "outputs": [],
      "source": [
        "!ls -l ~/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0pOxxkiGfGcN",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Generate curated MetFaces image without truncation\n",
        "!python generate.py --outdir=out --trunc=1 --seeds=85,265,297,849 \\\n",
        "    --network=https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/metfaces.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zj5zFA1jfGcN",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# display foler's images in 2x2\n",
        "def plot_images(img_dir, top=2):\n",
        "    all_img_dirs = os.listdir(img_dir)\n",
        "    img_files = [os.path.join(img_dir, file) for file in all_img_dirs]\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "\n",
        "    for idx, img_path in enumerate(img_files):\n",
        "        plt.subplot(2, 2, idx+1)\n",
        "\n",
        "        img = plt.imread(img_path)\n",
        "        plt.tight_layout()\n",
        "        plt.imshow(img, cmap='gray')\n",
        "        plt.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGy8ueEifGcN",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# display images in output folder\n",
        "plot_images('./out')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83Al-8W2fGcN",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Generate curated MetFaces image without truncation\n",
        "!python generate.py --outdir=out --trunc=1 --seeds=85,265,297,849 \\\n",
        "    --network=https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/ffhq.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6XQTh4cfGcN",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "plot_images('./out')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQQ1SZ3kfGcN"
      },
      "outputs": [],
      "source": [
        "!rm out/*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3SCzccefGcN",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Style mixing example\n",
        "!python style_mixing.py --outdir=out --rows=85,100,458,1500 --cols=55,821,1789,293 --styles=0-6  \\\n",
        "    --network=https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/metfaces.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RqxQHbdfGcN",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!ls out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjRZVUr1fGcN",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# display images in a row\n",
        "def plot_pics(img_files):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "\n",
        "    for i in range(len(img_files)):\n",
        "        plt.subplot(1, len(img_files), i+1)\n",
        "\n",
        "        img = plt.imread(img_files[i])\n",
        "        plt.tight_layout()\n",
        "        plt.imshow(img, cmap='gray')\n",
        "        plt.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJ9GKONhfGcN",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "files = ['out/100-100.png', 'out/1789-1789.png', 'out/100-1789.png']\n",
        "plot_pics(files)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRL56wNBfGcN"
      },
      "source": [
        "## Projecting images to latent space\n",
        "To find the matching latent vector for a given image file, run:\n",
        "\n",
        "    python projector.py --outdir=out --target=~/mytargetimg.png \\\n",
        "    --network=https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/ffhq.pkl\n",
        "    \n",
        "For optimal results, the target image should be cropped and aligned similar to the FFHQ dataset. The above command saves the projection target out/target.png, result out/proj.png, latent vector out/projected_w.npz, and progression video out/proj.mp4. You can render the resulting latent vector by specifying --projected_w for generate.py:\n",
        "    \n",
        "    python generate.py --outdir=out --projected_w=out/projected_w.npz \\\n",
        "    --network=https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/ffhq.pkl    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qf-BLALLfGcO"
      },
      "source": [
        "### download a picture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xJd7vHMfGcO",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!mkdir -p raw\n",
        "!wget https://upload.wikimedia.org/wikipedia/commons/6/6d/Shinz%C5%8D_Abe_Official.jpg -O raw/example.jpg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AhmznVqfGcO"
      },
      "source": [
        "### face alignment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAIeY3dJfGcO",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# face alignment\n",
        "!python align_images.py raw aligned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqhwEDC_fGcO",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!ls aligned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHwug6JYfGcO",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "files = ['raw/example.jpg', 'aligned/example_01.png']\n",
        "plot_pics(files)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVJ4M9ZmfGcO"
      },
      "source": [
        "## Projector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EoO58kumfGcO",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# projector\n",
        "!python projector.py --outdir=out --target=aligned/example_01.png \\\n",
        "    --network=https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/ffhq.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QTGocJEfGcO",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from IPython.display import Video\n",
        "Video('out/proj.mp4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-15T18:20:55.10733Z",
          "iopub.status.busy": "2022-11-15T18:20:55.106796Z",
          "iopub.status.idle": "2022-11-15T18:21:27.893909Z",
          "shell.execute_reply": "2022-11-15T18:21:27.893086Z",
          "shell.execute_reply.started": "2022-11-15T18:20:55.107294Z"
        },
        "id": "3DDLZnb0fGcO",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip uninstall jax jaxlib -y\n",
        "!pip install \"jax[cuda11_cudnn805]==0.3.10\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
        "# !git clone https://github.com/NVlabs/stylegan2-ada-pytorch.git\n",
        "!pip install ninja"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwHxc-91fGcO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Modify these to suit your needs\n",
        "EXPERIMENTS = \"./experiments\"\n",
        "NETWORK = \"network-snapshot-000120.pkl\"\n",
        "RESUME = os.path.join(EXPERIMENTS, \\\n",
        "                \"00003-mainplans1-auto2\", NETWORK)\n",
        "DATA = \"../input/mainplans/mainplans1\"\n",
        "SNAP = 35\n",
        "\n",
        "# Build the command and run it\n",
        "# cmd = f\"python3 ./stylegan2-ada-pytorch/train.py \"\\\n",
        "#   f\"--snap {SNAP} --resume {RESUME} --mirror=1 --aug=noaug --outdir {EXPERIMENTS} --data {DATA} --gpus=2\"\n",
        "\n",
        "import os\n",
        "os.system(f\"python3 ./stylegan2-ada-pytorch/train.py \"\\\n",
        "  f\"--snap {SNAP} --resume {RESUME} --mirror=1 --aug=noaug --outdir {EXPERIMENTS} --data {DATA} --gpus=2\")\n",
        "\n",
        "# !{cmd}"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 2637835,
          "sourceId": 4513430,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30123,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
