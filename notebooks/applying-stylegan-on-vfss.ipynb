{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training StyleGAN2-ADA on VFSS images\n",
    "Notebook with the shell commands used to train StyleGan2-ADA on VFSS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h7AfOlktfGcM",
    "outputId": "9551f9d8-8407-4c4e-bc0f-40e05ca6d708",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Cloning the StyleGAN3 repository \n",
    "# %cd ..\n",
    "# !git clone https://github.com/NVlabs/stylegan3\n",
    "# %pip install click requests tqdm pyspng ninja imageio-ffmpeg==0.4.3 scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MNj_so8cfGcM"
   },
   "source": [
    "## Optimizing dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd /workspace/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jOu_wP7bzyzd",
    "outputId": "e8a5c9a6-b806-4e1e-b0d5-bc536ede6dfc",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 17496/17496 [04:37<00:00, 63.13it/s]\n"
     ]
    }
   ],
   "source": [
    "!python stylegan3/dataset_tool.py \\\n",
    "    --source=data-synthesis-vfss/data/images/00000-all-frames-512 \\\n",
    "    --dest=data-synthesis-vfss/data/images/00000-all-frames-512.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparams set according to the [guide](https://github.com/NVlabs/stylegan3/blob/main/docs/configs.md) provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YDC1UxuwfGcM",
    "outputId": "2298e13e-5274-4c95-de82-7e1703afaf49",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training options:\n",
      "{\n",
      "  \"G_kwargs\": {\n",
      "    \"class_name\": \"training.networks_stylegan2.Generator\",\n",
      "    \"z_dim\": 512,\n",
      "    \"w_dim\": 512,\n",
      "    \"mapping_kwargs\": {\n",
      "      \"num_layers\": 2\n",
      "    },\n",
      "    \"channel_base\": 32768,\n",
      "    \"channel_max\": 512,\n",
      "    \"fused_modconv_default\": \"inference_only\"\n",
      "  },\n",
      "  \"D_kwargs\": {\n",
      "    \"class_name\": \"training.networks_stylegan2.Discriminator\",\n",
      "    \"block_kwargs\": {\n",
      "      \"freeze_layers\": 0\n",
      "    },\n",
      "    \"mapping_kwargs\": {},\n",
      "    \"epilogue_kwargs\": {\n",
      "      \"mbstd_group_size\": 4\n",
      "    },\n",
      "    \"channel_base\": 32768,\n",
      "    \"channel_max\": 512\n",
      "  },\n",
      "  \"G_opt_kwargs\": {\n",
      "    \"class_name\": \"torch.optim.Adam\",\n",
      "    \"betas\": [\n",
      "      0,\n",
      "      0.99\n",
      "    ],\n",
      "    \"eps\": 1e-08,\n",
      "    \"lr\": 0.0025\n",
      "  },\n",
      "  \"D_opt_kwargs\": {\n",
      "    \"class_name\": \"torch.optim.Adam\",\n",
      "    \"betas\": [\n",
      "      0,\n",
      "      0.99\n",
      "    ],\n",
      "    \"eps\": 1e-08,\n",
      "    \"lr\": 0.0025\n",
      "  },\n",
      "  \"loss_kwargs\": {\n",
      "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
      "    \"r1_gamma\": 1.6384,\n",
      "    \"style_mixing_prob\": 0.9,\n",
      "    \"pl_weight\": 2,\n",
      "    \"pl_no_weight_grad\": true\n",
      "  },\n",
      "  \"data_loader_kwargs\": {\n",
      "    \"pin_memory\": true,\n",
      "    \"prefetch_factor\": 2,\n",
      "    \"num_workers\": 3\n",
      "  },\n",
      "  \"training_set_kwargs\": {\n",
      "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
      "    \"path\": \"data-synthesis-vfss/data/images/00000-all-frames-512.zip\",\n",
      "    \"use_labels\": false,\n",
      "    \"max_size\": 17496,\n",
      "    \"xflip\": false,\n",
      "    \"resolution\": 512,\n",
      "    \"random_seed\": 0\n",
      "  },\n",
      "  \"num_gpus\": 2,\n",
      "  \"batch_size\": 32,\n",
      "  \"batch_gpu\": 16,\n",
      "  \"metrics\": [],\n",
      "  \"total_kimg\": 5000,\n",
      "  \"kimg_per_tick\": 4,\n",
      "  \"image_snapshot_ticks\": 25,\n",
      "  \"network_snapshot_ticks\": 25,\n",
      "  \"random_seed\": 0,\n",
      "  \"ema_kimg\": 10.0,\n",
      "  \"G_reg_interval\": 4,\n",
      "  \"augment_kwargs\": {\n",
      "    \"class_name\": \"training.augment.AugmentPipe\",\n",
      "    \"xflip\": 1,\n",
      "    \"rotate90\": 1,\n",
      "    \"xint\": 1,\n",
      "    \"scale\": 1,\n",
      "    \"rotate\": 1,\n",
      "    \"aniso\": 1,\n",
      "    \"xfrac\": 1,\n",
      "    \"brightness\": 1,\n",
      "    \"contrast\": 1,\n",
      "    \"lumaflip\": 1,\n",
      "    \"hue\": 1,\n",
      "    \"saturation\": 1\n",
      "  },\n",
      "  \"ada_target\": 0.6,\n",
      "  \"run_dir\": \"data-synthesis-vfss/data/training-runs/00001-stylegan2-00000-all-frames-512-gpus2-batch32-gamma1.6384\"\n",
      "}\n",
      "\n",
      "Output directory:    data-synthesis-vfss/data/training-runs/00001-stylegan2-00000-all-frames-512-gpus2-batch32-gamma1.6384\n",
      "Number of GPUs:      2\n",
      "Batch size:          32 images\n",
      "Training duration:   5000 kimg\n",
      "Dataset path:        data-synthesis-vfss/data/images/00000-all-frames-512.zip\n",
      "Dataset size:        17496 images\n",
      "Dataset resolution:  512\n",
      "Dataset labels:      False\n",
      "Dataset x-flips:     False\n",
      "\n",
      "Creating output directory...\n",
      "Launching processes...\n",
      "Loading training set...\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/sampler.py:76: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/sampler.py:76: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.\n",
      "  warnings.warn(\n",
      "\n",
      "Num images:  17496\n",
      "Image shape: [3, 512, 512]\n",
      "Label shape: [0]\n",
      "\n",
      "Constructing networks...\n",
      "Setting up PyTorch plugin \"bias_act_plugin\"... /usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "Done.\n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... /usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "Done.\n",
      "\n",
      "Generator             Parameters  Buffers  Output shape         Datatype\n",
      "---                   ---         ---      ---                  ---     \n",
      "mapping.fc0           262656      -        [16, 512]            float32 \n",
      "mapping.fc1           262656      -        [16, 512]            float32 \n",
      "mapping               -           512      [16, 16, 512]        float32 \n",
      "synthesis.b4.conv1    2622465     32       [16, 512, 4, 4]      float32 \n",
      "synthesis.b4.torgb    264195      -        [16, 3, 4, 4]        float32 \n",
      "synthesis.b4:0        8192        16       [16, 512, 4, 4]      float32 \n",
      "synthesis.b4:1        -           -        [16, 3, 4, 4]        float32 \n",
      "synthesis.b8.conv0    2622465     80       [16, 512, 8, 8]      float32 \n",
      "synthesis.b8.conv1    2622465     80       [16, 512, 8, 8]      float32 \n",
      "synthesis.b8.torgb    264195      -        [16, 3, 8, 8]        float32 \n",
      "synthesis.b8:0        -           16       [16, 512, 8, 8]      float32 \n",
      "synthesis.b8:1        -           -        [16, 3, 8, 8]        float32 \n",
      "synthesis.b16.conv0   2622465     272      [16, 512, 16, 16]    float32 \n",
      "synthesis.b16.conv1   2622465     272      [16, 512, 16, 16]    float32 \n",
      "synthesis.b16.torgb   264195      -        [16, 3, 16, 16]      float32 \n",
      "synthesis.b16:0       -           16       [16, 512, 16, 16]    float32 \n",
      "synthesis.b16:1       -           -        [16, 3, 16, 16]      float32 \n",
      "synthesis.b32.conv0   2622465     1040     [16, 512, 32, 32]    float32 \n",
      "synthesis.b32.conv1   2622465     1040     [16, 512, 32, 32]    float32 \n",
      "synthesis.b32.torgb   264195      -        [16, 3, 32, 32]      float32 \n",
      "synthesis.b32:0       -           16       [16, 512, 32, 32]    float32 \n",
      "synthesis.b32:1       -           -        [16, 3, 32, 32]      float32 \n",
      "synthesis.b64.conv0   2622465     4112     [16, 512, 64, 64]    float16 \n",
      "synthesis.b64.conv1   2622465     4112     [16, 512, 64, 64]    float16 \n",
      "synthesis.b64.torgb   264195      -        [16, 3, 64, 64]      float16 \n",
      "synthesis.b64:0       -           16       [16, 512, 64, 64]    float16 \n",
      "synthesis.b64:1       -           -        [16, 3, 64, 64]      float32 \n",
      "synthesis.b128.conv0  1442561     16400    [16, 256, 128, 128]  float16 \n",
      "synthesis.b128.conv1  721409      16400    [16, 256, 128, 128]  float16 \n",
      "synthesis.b128.torgb  132099      -        [16, 3, 128, 128]    float16 \n",
      "synthesis.b128:0      -           16       [16, 256, 128, 128]  float16 \n",
      "synthesis.b128:1      -           -        [16, 3, 128, 128]    float32 \n",
      "synthesis.b256.conv0  426369      65552    [16, 128, 256, 256]  float16 \n",
      "synthesis.b256.conv1  213249      65552    [16, 128, 256, 256]  float16 \n",
      "synthesis.b256.torgb  66051       -        [16, 3, 256, 256]    float16 \n",
      "synthesis.b256:0      -           16       [16, 128, 256, 256]  float16 \n",
      "synthesis.b256:1      -           -        [16, 3, 256, 256]    float32 \n",
      "synthesis.b512.conv0  139457      262160   [16, 64, 512, 512]   float16 \n",
      "synthesis.b512.conv1  69761       262160   [16, 64, 512, 512]   float16 \n",
      "synthesis.b512.torgb  33027       -        [16, 3, 512, 512]    float16 \n",
      "synthesis.b512:0      -           16       [16, 64, 512, 512]   float16 \n",
      "synthesis.b512:1      -           -        [16, 3, 512, 512]    float32 \n",
      "---                   ---         ---      ---                  ---     \n",
      "Total                 28700647    699904   -                    -       \n",
      "\n",
      "\n",
      "Discriminator  Parameters  Buffers  Output shape         Datatype\n",
      "---            ---         ---      ---                  ---     \n",
      "b512.fromrgb   256         16       [16, 64, 512, 512]   float16 \n",
      "b512.skip      8192        16       [16, 128, 256, 256]  float16 \n",
      "b512.conv0     36928       16       [16, 64, 512, 512]   float16 \n",
      "b512.conv1     73856       16       [16, 128, 256, 256]  float16 \n",
      "b512           -           16       [16, 128, 256, 256]  float16 \n",
      "b256.skip      32768       16       [16, 256, 128, 128]  float16 \n",
      "b256.conv0     147584      16       [16, 128, 256, 256]  float16 \n",
      "b256.conv1     295168      16       [16, 256, 128, 128]  float16 \n",
      "b256           -           16       [16, 256, 128, 128]  float16 \n",
      "b128.skip      131072      16       [16, 512, 64, 64]    float16 \n",
      "b128.conv0     590080      16       [16, 256, 128, 128]  float16 \n",
      "b128.conv1     1180160     16       [16, 512, 64, 64]    float16 \n",
      "b128           -           16       [16, 512, 64, 64]    float16 \n",
      "b64.skip       262144      16       [16, 512, 32, 32]    float16 \n",
      "b64.conv0      2359808     16       [16, 512, 64, 64]    float16 \n",
      "b64.conv1      2359808     16       [16, 512, 32, 32]    float16 \n",
      "b64            -           16       [16, 512, 32, 32]    float16 \n",
      "b32.skip       262144      16       [16, 512, 16, 16]    float32 \n",
      "b32.conv0      2359808     16       [16, 512, 32, 32]    float32 \n",
      "b32.conv1      2359808     16       [16, 512, 16, 16]    float32 \n",
      "b32            -           16       [16, 512, 16, 16]    float32 \n",
      "b16.skip       262144      16       [16, 512, 8, 8]      float32 \n",
      "b16.conv0      2359808     16       [16, 512, 16, 16]    float32 \n",
      "b16.conv1      2359808     16       [16, 512, 8, 8]      float32 \n",
      "b16            -           16       [16, 512, 8, 8]      float32 \n",
      "b8.skip        262144      16       [16, 512, 4, 4]      float32 \n",
      "b8.conv0       2359808     16       [16, 512, 8, 8]      float32 \n",
      "b8.conv1       2359808     16       [16, 512, 4, 4]      float32 \n",
      "b8             -           16       [16, 512, 4, 4]      float32 \n",
      "b4.mbstd       -           -        [16, 513, 4, 4]      float32 \n",
      "b4.conv        2364416     16       [16, 512, 4, 4]      float32 \n",
      "b4.fc          4194816     -        [16, 512]            float32 \n",
      "b4.out         513         -        [16, 1]              float32 \n",
      "---            ---         ---      ---                  ---     \n",
      "Total          28982849    480      -                    -       \n",
      "\n",
      "Setting up augmentation...\n",
      "Distributing across 2 GPUs...\n",
      "Setting up training phases...\n",
      "Exporting sample images...\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Train model from scratch\n",
    "!python stylegan3/train.py \\\n",
    "  --outdir=data-synthesis-vfss/data/training-runs \\\n",
    "  --data=data-synthesis-vfss/data/images/00000-all-frames-512.zip \\\n",
    "  --cfg=stylegan2 \\\n",
    "  --kimg=5000 \\\n",
    "  --snap=25 \\\n",
    "  --gpus=2 \\\n",
    "  --batch=32 \\\n",
    "  --gamma=1.6384 \\\n",
    "  --map-depth=2 \\\n",
    "  --glr=0.0025 \\\n",
    "  --dlr=0.0025 \\\n",
    "  --metrics=none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Resume model training\n",
    "\n",
    "# !python stylegan3/train.py \\\n",
    "#   --resume=data-synthesis-vfss/training-runs/00000-stylegan2-max_constriction-gpus2-batch32-gamma0.8192/network-snapshot-001000.pkl \\\n",
    "#   --outdir=data-synthesis-vfss/training-runs \\\n",
    "#   --data=data-synthesis-vfss/data/images/max_constriction.zip \\\n",
    "#   --cfg=stylegan2 \\\n",
    "#   --gpus=2 \\\n",
    "#   --batch=32 \\\n",
    "#   --gamma=0.8192 \\\n",
    "#   --map-depth=2 \\\n",
    "#   --glr=0.0025 \\\n",
    "#   --dlr=0.0025 \\\n",
    "#   --cbase=16384 \\\n",
    "#   --kimg=4000 \\\n",
    "#   --metrics=none \\\n",
    "#   # --tick=1 \\\n",
    "#   --snap=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YKbdO_LNfGcM"
   },
   "source": [
    "## Generate instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0pOxxkiGfGcN",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading networks from \"data-synthesis-vfss/training-runs/00000-stylegan2-max_constriction-gpus2-batch32-gamma0.8192/network-snapshot-001000.pkl\"...\n",
      "Generating image for seed 85 (0/4) ...\n",
      "Setting up PyTorch plugin \"bias_act_plugin\"... /usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "Done.\n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... /usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "Done.\n",
      "Generating image for seed 265 (1/4) ...\n",
      "Generating image for seed 297 (2/4) ...\n",
      "Generating image for seed 849 (3/4) ...\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic VFSS images\n",
    "!python  stylegan3/gen_images.py \\\n",
    "    --outdir=out \\\n",
    "    --trunc=1 \\\n",
    "    --seeds=85,265,297,849 \\\n",
    "    --network=data-synthesis-vfss/training-runs/00000-stylegan2-max_constriction-gpus2-batch32-gamma0.8192/network-snapshot-001000.pkl\n",
    "    # --network=https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/metfaces.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zj5zFA1jfGcN",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# display foler's images in 2x2\n",
    "def plot_images(img_dir, top=2):\n",
    "    all_img_dirs = os.listdir(img_dir)\n",
    "    img_files = [os.path.join(img_dir, file) for file in all_img_dirs]\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    for idx, img_path in enumerate(img_files):\n",
    "        plt.subplot(2, 2, idx+1)\n",
    "\n",
    "        img = plt.imread(img_path)\n",
    "        plt.tight_layout()\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KGy8ueEifGcN",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# display images in output folder\n",
    "plot_images('./out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i6XQTh4cfGcN",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "plot_images('./out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rQQ1SZ3kfGcN",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "!rm out/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WjRZVUr1fGcN",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# display images in a row\n",
    "def plot_pics(img_files):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    for i in range(len(img_files)):\n",
    "        plt.subplot(1, len(img_files), i+1)\n",
    "\n",
    "        img = plt.imread(img_files[i])\n",
    "        plt.tight_layout()\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XJ9GKONhfGcN",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "files = ['out/100-100.png', 'out/1789-1789.png', 'out/100-1789.png']\n",
    "plot_pics(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jRL56wNBfGcN"
   },
   "source": [
    "## Projecting images to latent space\n",
    "\n",
    "To find the matching latent vector for a given image file, run:\n",
    "\n",
    "    python projector.py --outdir=out --target=~/mytargetimg.png \\\n",
    "    --network=https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/ffhq.pkl\n",
    "    \n",
    "For optimal results, the target image should be cropped and aligned similar to the FFHQ dataset. The above command saves the projection target out/target.png, result out/proj.png, latent vector out/projected_w.npz, and progression video out/proj.mp4. You can render the resulting latent vector by specifying --projected_w for generate.py:\n",
    "    \n",
    "    python generate.py --outdir=out --projected_w=out/projected_w.npz \\\n",
    "    --network=https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/ffhq.pkl    \n",
    "\n",
    "Reference: [rkuo2000](https://www.kaggle.com/code/rkuo2000/stylegan2-ada)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qf-BLALLfGcO"
   },
   "source": [
    "### download a picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5xJd7vHMfGcO",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "!mkdir -p raw\n",
    "!wget https://upload.wikimedia.org/wikipedia/commons/6/6d/Shinz%C5%8D_Abe_Official.jpg -O raw/example.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4AhmznVqfGcO"
   },
   "source": [
    "### face alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nAIeY3dJfGcO",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# face alignment\n",
    "!python align_images.py raw aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qqhwEDC_fGcO",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "!ls aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kHwug6JYfGcO",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "files = ['raw/example.jpg', 'aligned/example_01.png']\n",
    "plot_pics(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pVJ4M9ZmfGcO"
   },
   "source": [
    "## Projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EoO58kumfGcO",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# projector\n",
    "!python projector.py --outdir=out --target=aligned/example_01.png \\\n",
    "    --network=https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/ffhq.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2QTGocJEfGcO",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "Video('out/proj.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-15T18:20:55.10733Z",
     "iopub.status.busy": "2022-11-15T18:20:55.106796Z",
     "iopub.status.idle": "2022-11-15T18:21:27.893909Z",
     "shell.execute_reply": "2022-11-15T18:21:27.893086Z",
     "shell.execute_reply.started": "2022-11-15T18:20:55.107294Z"
    },
    "id": "3DDLZnb0fGcO",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "%pip uninstall jax jaxlib -y\n",
    "%pip install \"jax[cuda11_cudnn805]==0.3.10\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
    "# !git clone https://github.com/NVlabs/stylegan2-ada-pytorch.git\n",
    "%pip install ninja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cwHxc-91fGcO",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Modify these to suit your needs\n",
    "EXPERIMENTS = \"./experiments\"\n",
    "NETWORK = \"network-snapshot-000120.pkl\"\n",
    "RESUME = os.path.join(EXPERIMENTS, \\\n",
    "                \"00003-mainplans1-auto2\", NETWORK)\n",
    "DATA = \"../input/mainplans/mainplans1\"\n",
    "SNAP = 35\n",
    "\n",
    "# Build the command and run it\n",
    "# cmd = f\"python3 ./stylegan2-ada-pytorch/train.py \"\\\n",
    "#   f\"--snap {SNAP} --resume {RESUME} --mirror=1 --aug=noaug --outdir {EXPERIMENTS} --data {DATA} --gpus=2\"\n",
    "\n",
    "import os\n",
    "os.system(f\"python3 ./stylegan2-ada-pytorch/train.py \"\\\n",
    "  f\"--snap {SNAP} --resume {RESUME} --mirror=1 --aug=noaug --outdir {EXPERIMENTS} --data {DATA} --gpus=2\")\n",
    "\n",
    "# !{cmd}"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 2637835,
     "sourceId": 4513430,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30123,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
